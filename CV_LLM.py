# -*- coding: utf-8 -*-
"""YOLO11 Tutorial

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb
"""

from transformers import pipeline

checkpoint = "google/owlv2-base-patch16-ensemble"
detector = pipeline(model=checkpoint, task="zero-shot-object-detection")

import skimage
import numpy as np
from PIL import Image

image = skimage.data.astronaut()
image = Image.fromarray(np.uint8(image)).convert("RGB")

image

import langchain
from transformers import pipeline
# Removed the incorrect LangChain initialization
# lc = langchain.LangChain()

def extract_names(document):
    # LangChain initialization
    # lc = langchain.LangChain() # This line caused the error and is removed

    # Tokenize the document into sentences
    sentences = document.split('.')

    names = []
    for sentence in sentences:
        # It's unclear how you intended to use embeddings for name extraction here.
        # The original code had a placeholder logic based on token length.
        # To use embeddings, you would typically load an embedding model from LangChain
        # and then apply some logic based on the embeddings.
        # For demonstration, I'll keep the original placeholder logic (token length > 5)
        # but note that this does not use embeddings.
        extracted_tokens = [token for token in sentence.split() if len(token) > 5]
        names.extend(extracted_tokens)

    return names

def extract_names_with_hugging_face_pipelines(document):
    # Using LangChain for text embedding
    extracted_names = extract_names(document)

    # Using Hugging Face pipeline for DistilBERT
    ner_pipeline = pipeline("ner", model="distilbert-base-uncased", tokenizer="distilbert-base-uncased")

    names = []
    for name_token in extracted_names:
        # Apply NER using pipeline
        entities = ner_pipeline(name_token)

        if entities and entities[0]['entity'] == 'B-PER':  # Checking if it's a person entity
            names.append(name_token)

    return names

document = "John Smith and Sarah Johnson attended the conference. Emily Brown was the keynote speaker."
extracted_names = extract_names_with_hugging_face_pipelines(document)
print("Extracted Names:", extracted_names)

predictions = detector(
    image,
    candidate_labels= extracted_names,
)
predictions



